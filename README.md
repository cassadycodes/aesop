This project extracted moral themes from folklore stories via a text-generation approach using few-shot learning with the large language model GPT-J-6B. The model is shown several examples (seed stories) of Aesop’s Fables, complete with the author’s original moral lesson, then shown another text alone, with the moral lesson left blank for the model to generate. Annotators rated the similarity of the original moral to the model’s generated moral. If the generated moral did not match the meaning of the original, annotators also rated whether the generated moral matched the context of the story. The second experiment uses Aesops as few-shot examples, but the final prompt text is selected from a global folktales collection, which do not have original morals from the authors. On the first run, the seed story is randomly selected from Aesop’s Fables. On the second run, only Aesops that annotators identified as having generated a moral that agreed with the original (good seeds) were used as seed stories. Cosine similarity of embeddings between original and generated morals received a mean F-1 score of 73% via BERTscore. 
